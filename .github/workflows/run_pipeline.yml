name: Run HR Report Pipeline

on:
  workflow_dispatch:
    inputs:
      date:
        description: 'Report date (MM/DD/YYYY). Leave blank for most recent date in sheet.'
        required: false
        default: ''
      end_date:
        description: 'Pay period end date (MM/DD/YYYY). Leave blank to match report date.'
        required: false
        default: ''
      skip_upload:
        description: 'Skip S3 upload (just generate Excel as artifact)'
        required: false
        type: boolean
        default: false

  # Uncomment to run on a schedule (e.g. every weekday at 7am UTC):
  # schedule:
  #   - cron: '0 7 * * 1-5'

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Write service account key file
        env:
          SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
        run: printenv SERVICE_ACCOUNT_JSON > service_account.json

      - name: Create .env file
        env:
          SHEETS_ID: ${{ secrets.GOOGLE_SHEETS_SPREADSHEET_ID }}
          AWS_KEY: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION_VAL: ${{ secrets.AWS_REGION }}
          S3_BUCKET: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          printf '%s\n' \
            "GOOGLE_SHEETS_SPREADSHEET_ID=${SHEETS_ID}" \
            "GOOGLE_SHEETS_RANGE=Sheet1" \
            "GOOGLE_SERVICE_ACCOUNT_FILE=service_account.json" \
            "AWS_ACCESS_KEY_ID=${AWS_KEY}" \
            "AWS_SECRET_ACCESS_KEY=${AWS_SECRET}" \
            "AWS_REGION=${AWS_REGION_VAL}" \
            "S3_BUCKET_NAME=${S3_BUCKET}" \
            "S3_PREFIX=hr-reports/" \
            "OUTPUT_DIR=output" \
            "OUTPUT_FILENAME_PREFIX=HR_Report" \
            > .env

      - name: Verify config
        run: |
          echo "=== service_account.json ==="
          echo "exists: $(test -f service_account.json && echo yes || echo no)"
          echo "size: $(wc -c < service_account.json) bytes"
          python3 -c "
          import json
          with open('service_account.json') as f:
              data = json.load(f)
          print(f\"type: {data.get('type')}\")
          print(f\"project_id: {data.get('project_id')}\")
          print(f\"client_email: {data.get('client_email')}\")
          print(f\"has private_key: {'private_key' in data}\")
          print(f\"private_key starts with: {data.get('private_key','')[:30]}\")
          "
          echo ""
          echo "=== .env ==="
          echo "line count: $(wc -l < .env)"
          echo "Spreadsheet ID value (first 10 chars): $(grep GOOGLE_SHEETS_SPREADSHEET_ID .env | cut -d= -f2 | cut -c1-10)"
          echo "Spreadsheet ID length: $(grep GOOGLE_SHEETS_SPREADSHEET_ID .env | cut -d= -f2 | tr -d '\n' | wc -c)"

      - name: Test sheets access
        run: |
          python3 -c "
          from dotenv import load_dotenv
          load_dotenv()
          import os
          sid = os.getenv('GOOGLE_SHEETS_SPREADSHEET_ID', '')
          print(f'Spreadsheet ID from env: [{sid}]')
          print(f'Length: {len(sid)}')
          print(f'First 10: {sid[:10]}')
          print(f'Last 10: {sid[-10:]}')

          from google.oauth2.service_account import Credentials
          creds = Credentials.from_service_account_file(
              'service_account.json',
              scopes=['https://www.googleapis.com/auth/spreadsheets.readonly']
          )
          print(f'Auth email: {creds.service_account_email}')
          print(f'Project: {creds.project_id}')
          print('Credentials loaded OK')
          "

      - name: Run pipeline
        run: |
          ARGS=""
          if [ "${{ inputs.skip_upload }}" = "true" ] || [ -z "${{ secrets.S3_BUCKET_NAME }}" ]; then
            ARGS="$ARGS --skip-upload"
          fi
          if [ -n "${{ inputs.date }}" ]; then
            ARGS="$ARGS --date ${{ inputs.date }}"
          fi
          if [ -n "${{ inputs.end_date }}" ]; then
            ARGS="$ARGS --end-date ${{ inputs.end_date }}"
          fi
          python main.py $ARGS

      - name: Upload Excel as artifact
        uses: actions/upload-artifact@v4
        with:
          name: hr-report
          path: output/*.xlsx
          retention-days: 30

      - name: Clean up secrets
        if: always()
        run: rm -f service_account.json .env
